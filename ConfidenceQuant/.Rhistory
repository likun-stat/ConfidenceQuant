devtools::document()
library(ConfidenceQuant)
library("ConfidenceQuant", lib.loc="/usr/local/lib/R/site-library")
data(treatment)
data(control)
all<-CompExperiment_1dim_boot(cores=7, treatment, control, tau=0.5, B=2, Search=TRUE)
devtools::document()
all<-CompExperiment_1dim_boot(cores=7, treatment, control, tau=0.5, B=2, Search=TRUE)
plot<-CompPlot_1dim(treatment = treatment, control=control, all = all, xlab = 'x', ylab = 'y')
plot
plot(all$result1$Lambda,all$result1$Fid,type='l')
plot(all$result2$Lambda,all$result2$Fid,type='l')
devtools::document()
library(ConfidenceQuant)
?CompExperiment_2dim_boot
data(treatment_2dim)
data(control_2dim)
#alpha=0.05;tau=0.5
all<-CompExperiment_2dim_boot(cores=7, treatment_2dim, control_2dim, tau=0.5, Search=TRUE,B=3)
devtools::document()
data(treatment_2dim)
data(control_2dim)
#alpha=0.05;tau=0.5
all<-CompExperiment_2dim_boot(cores=7, treatment_2dim, control_2dim, tau=0.5, Search=TRUE,B=3)
plot<-CompPlot_2dim(control = control_2dim,treatment = treatment_2dim,all = all,xlab="x1",
ylab="x2",zlab="z")
plot
plot$trace
devtools::document()
library("ConfidenceQuant", lib.loc="/usr/local/lib/R/site-library")
?CompExperiment_1dim_boot
?CompExperiment_2dim_boot
1+1
detach("package:ConfidenceQuant", unload=TRUE)
library("ConfidenceQuant", lib.loc="/usr/local/lib/R/site-library")
detach("package:ConfidenceQuant", unload=TRUE)
devtools::document()
install.packages("devtools")
devtools::document()
install.packages("roxygen2")
devtools::document()
library(ConfidenceQuant)
?Vignette_data
devtools::document()
?sim.data
load(sim.data)
data(sim.data)
devtools::document()
devtools::document()
?FoldsGenerator
devtools::document()
devtools::document()
?foldsGenerator
data(sim.data)
devtools::document()
data(re)
save(re,file="re.RData")
devtools::document()
data(re)
BLB_rqss<-function(cores=NULL,data,alpha=0.05,tau=0.25,lambda=2,D=100,b=ceiling(nrow(data)^0.6), s=15, r=100, Search=FALSE){
set.seed(100)
if(is.null(cores)) {cores=round(0.5*detectCores())}
registerDoParallel(cores=cores)
if(!all(colnames(data)==c("x","y"))) colnames(data)<-c("x","y")
###1. Sample s disjoint subsets with size b
n<-nrow(data)
shuffle<-sample(1:n)
indices<-matrix(head(shuffle,b*s),nrow=s,byrow=TRUE)
Rboot<-rmultinom(s,size=n,prob=rep(1/b,b))
indicator<-(Search|length(lambda)>1)
###2. λ Search
if(indicator){
if(length(lambda)>1) Lambda<-lambda else Lambda<-c(seq(0,400,by=10),500,1000,1500,2000,3000)
fid<-rep(NA,length(Lambda))
Fid<-foreach(j=1:s,.combine = "cbind") %dopar% {
subsample<-data[indices[j,],]
for(f in 1:length(Lambda)){
mod <- rqss_new(y ~ qss(x, lambda = Lambda[f]), tau = tau, data = subsample, weights = as.vector(Rboot[,j]))
fid_rec<-0
for(p in (1:s)[-j]){
testdata<-data[indices[p,],]
extrapolated<-(testdata$x > max(subsample$x) | testdata$x < min(subsample$x))
y.pred<-predict(mod, newdata = testdata[!extrapolated,])
temp<-as.vector(Rboot[,p])[!extrapolated]
fid_rec<-fid_rec+sum(temp*rho(tau=tau, testdata$y[!extrapolated]-y.pred))/sum(temp)
}
fid[f]<-fid_rec/(s-1)
}
return(fid)
}
#plot(Lambda[-1],rowMeans(Fid)[-1],type='l',ylab="New Metric",xlab="λ",main="MCV for BLB repeated data")
Fidelity<-rowMeans(Fid)
lambda<-Lambda[which.min(Fidelity)]
}
###3. Bag of Little Bootstrap
xrange<-range(data$x)
x0 <- seq(xrange[1], xrange[2], by = diff(xrange)/D)
response <- rep(NA,length(x0))   #Prediction for one bootstrap sample
Response<-matrix(nrow=length(x0),ncol=r)
CIs<-foreach (j=1:s) %dopar% {
subsample<-data[indices[j,],]
extrapolated = x0 > max(subsample$x) | x0 < min(subsample$x)
for(k in 1:r){
response[1:length(x0)] <- NA
rboot<-as.vector(rmultinom(1,size=n,prob=rep(1/b,b)))
mod <- rqss_new(y ~ qss(x, lambda = lambda), tau = tau, data = subsample, weights = rboot)
response[!extrapolated] = predict(mod, newdata = data.frame(x=x0[!extrapolated]))
Response[,k]<-response
}
return(t(apply(Response,1,function(x) quantile(x, probs=c(alpha/2,1-alpha/2),na.rm=TRUE))))
#t(apply(Response,1,function(x) quantile(x, probs=c(alpha/(2*p),1-alpha/(2*p)),na.rm=TRUE)))
}
#Average CI bounds computed for different data subsets
IsNull<-rep(TRUE,length(CIs))
for(j in 1:length(CIs)){
if(is.null(CIs[[j]])) IsNull[j]<-FALSE
}
CIs<-CIs[IsNull]
CI_average<-matrix(NA,nrow = length(x0), ncol = 2)
for(i in 1:length(x0)){
times<-0
ci<-rep(0,2)
for (j in 1:length(CIs)){
if(!is.na(CIs[[j]][i,1]))  {times<-times+1;ci<-ci+CIs[[j]][i,]}
}
CI_average[i,]<-ci/times
}
if(indicator) return(list(x0=x0, CI_average=CI_average, lambda=lambda, Lambda=Lambda, Fid=Fidelity))
else return(list(x0=x0, CI_average=CI_average, lambda=lambda))
#R CMD Rd2pdf ConfidenceQuant
}
BLB_rqss<-function(cores=NULL,data,alpha=0.05,tau=0.25,lambda=2,D=100,b=ceiling(nrow(data)^0.6), s=15, r=100, Search=FALSE){
set.seed(100)
if(is.null(cores)) {cores=round(0.5*detectCores())}
registerDoParallel(cores=cores)
if(!all(colnames(data)==c("x","y"))) colnames(data)<-c("x","y")
###1. Sample s disjoint subsets with size b
n<-nrow(data)
shuffle<-sample(1:n)
indices<-matrix(head(shuffle,b*s),nrow=s,byrow=TRUE)
Rboot<-rmultinom(s,size=n,prob=rep(1/b,b))
indicator<-(Search|length(lambda)>1)
###2. λ Search
if(indicator){
if(length(lambda)>1) Lambda<-lambda else Lambda<-c(seq(0,400,by=10),500,1000,1500,2000,3000)
fid<-rep(NA,length(Lambda))
Fid<-foreach(j=1:s,.combine = "cbind") %dopar% {
subsample<-data[indices[j,],]
for(f in 1:length(Lambda)){
mod <- rqss_new(y ~ qss(x, lambda = Lambda[f]), tau = tau, data = subsample, weights = as.vector(Rboot[,j]))
fid_rec<-0
for(p in (1:s)[-j]){
testdata<-data[indices[p,],]
extrapolated<-(testdata$x > max(subsample$x) | testdata$x < min(subsample$x))
y.pred<-predict(mod, newdata = testdata[!extrapolated,])
temp<-as.vector(Rboot[,p])[!extrapolated]
fid_rec<-fid_rec+sum(temp*rho(tau=tau, testdata$y[!extrapolated]-y.pred))/sum(temp)
}
fid[f]<-fid_rec/(s-1)
}
return(fid)
}
#plot(Lambda[-1],rowMeans(Fid)[-1],type='l',ylab="New Metric",xlab="λ",main="MCV for BLB repeated data")
Fidelity<-rowMeans(Fid)
lambda<-Lambda[which.min(Fidelity)]
}
###3. Bag of Little Bootstrap
xrange<-range(data$x)
x0 <- seq(xrange[1], xrange[2], by = diff(xrange)/D)
response <- rep(NA,length(x0))   #Prediction for one bootstrap sample
Response<-matrix(nrow=length(x0),ncol=r)
CIs<-foreach (j=1:s) %dopar% {
subsample<-data[indices[j,],]
extrapolated = x0 > max(subsample$x) | x0 < min(subsample$x)
for(k in 1:r){
response[1:length(x0)] <- NA
rboot<-as.vector(rmultinom(1,size=n,prob=rep(1/b,b)))
mod <- rqss_new(y ~ qss(x, lambda = lambda), tau = tau, data = subsample, weights = rboot)
response[!extrapolated] = predict(mod, newdata = data.frame(x=x0[!extrapolated]))
Response[,k]<-response
}
return(t(apply(Response,1,function(x) quantile(x, probs=c(alpha/2,1-alpha/2),na.rm=TRUE))))
#t(apply(Response,1,function(x) quantile(x, probs=c(alpha/(2*p),1-alpha/(2*p)),na.rm=TRUE)))
}
#Average CI bounds computed for different data subsets
IsNull<-rep(TRUE,length(CIs))
for(j in 1:length(CIs)){
if(is.null(CIs[[j]])) IsNull[j]<-FALSE
}
CIs<-CIs[IsNull]
CI_average<-matrix(NA,nrow = length(x0), ncol = 2)
for(i in 1:length(x0)){
times<-0
ci<-rep(0,2)
for (j in 1:length(CIs)){
if(!is.na(CIs[[j]][i,1]))  {times<-times+1;ci<-ci+CIs[[j]][i,]}
}
CI_average[i,]<-ci/times
}
if(indicator) return(list(x0=x0, CI_average=CI_average, lambda=lambda, Lambda=Lambda, Fid=Fidelity))
else return(list(x0=x0, CI_average=CI_average, lambda=lambda))
#R CMD Rd2pdf ConfidenceQuant
}
devtools::document()
foldsGenerator()
foldsGenerator
foldsGenerator(sim.data=data.frame(),n=nrow(sim.data),nfolds=nfolds)
foldsGenerator(sim.data=data.frame(),n=nrow(sim.data),nfolds=10)
devtools::document()
summary(sim.data)
data(sim.data)
summary(sim.data)
summary(sim.data1)
data(sim.data1)
summary(sim.data)
data(sim.data1)->sim.data
sim.data
devtools::document()
foldsGenerator()
foldsGenerator
set.seed(100)
f1<-function(x) sin(2*pi*x)
tau=0.5
n<-5000
x<-runif(n,-1,1)
e0<-rnorm(n,sd=0.5)
y<-x^2+e0
sim.data<-data.frame(x=x,y=y)
tau<-0.5
Lambda<-seq(0.0005,0.1,by=0.0005)
Edf<-rep(0,length(Lambda))
Fid<-rep(0,length(Lambda))
for(i in 1:length(Lambda)){
mod <- rqss(y ~ qss(x, lambda = Lambda[i]), tau = tau, data = sim.data)
Fid[i]<-mod$fidelity
Edf[i]<-mod$edf
}
plot(Lambda[-(1)],Edf[-(1)],type="l",xlab=expression(lambda),ylab=expression(p(lambda)),main="Effective Degrees of Freedom")
plot(Lambda[-(1)],(log(Fid/n)+(1/2)*(1/n)*Edf*log(n))[-(1)],type="l",xlab=expression(lambda),ylab="SIC",main=expression(paste("SIC(",lambda,") criterion")))
plot(Lambda,Fid/(n-Edf),type="l",xlab=expression(lambda),ylab="GACV",main="GACV criterion")
l1<-Lambda[16]
l2<-Lambda[17]
mod1 <- rqss(y ~ qss(x, lambda = l1), tau = tau, data = sim.data)
mod2 <- rqss(y ~ qss(x, lambda = l2), tau = tau, data = sim.data)
plot(sim.data,col="grey")
subset1<-which(abs(resid.rqss(mod1))<1e-5)
points(sim.data[subset1,],pch=20,col="red")
new.data<-data.frame(x=sort(c(seq(-0.999,0.999,by=0.0001),unique(sim.data$x))))
pred1<-predict(mod1,newdata=new.data)
lines(as.vector(t(new.data)),pred1)
plot(sim.data,col="grey")
subset2<-which(abs(resid.rqss(mod2))<1e-5)
points(sim.data[subset2,],pch=20,col="blue")
new.data<-data.frame(x=sort(c(seq(-0.999,0.999,by=0.0001),unique(sim.data$x))))
pred2<-predict(mod2,newdata=new.data)
lines(as.vector(t(new.data)),pred2)
nfolds<-10
cv.idx<-foldsGenerator(sim.data,n=nrow(sim.data),nfolds=nfolds)
require(doParallel)
require(foreach)
registerDoParallel(cores=3)
Lambda<-seq(0.001,4,by=0.02)
MCV<-rep(NA,length(Lambda))
for(m in 1:length(Lambda)){
## loop through, holding out one set of data at each point
Fid<-foreach(i = 1:nfolds,.combine="c")%dopar%{
hold.out.idx=which(cv.idx==i)
keep.in.data<-sim.data[-hold.out.idx,]
mod <- rqss(y ~ qss(x, lambda =Lambda[m]), tau = tau, data = keep.in.data)
new.data<-sim.data[hold.out.idx,]
extrapolated <- new.data$x > max(keep.in.data$x) | new.data$x < min(keep.in.data$x)
y.pred<-as.vector(predict(mod,newdata=new.data[!extrapolated,]))
mean(rho(tau=tau,x=new.data$y[!extrapolated]-y.pred))
}
MCV[m]<-mean(Fid)
}
plot(Lambda[-1], MCV[-1],type='l',xlab=expression(lambda),ylab='MCV')
abline(v=Lambda[which.min(MCV)],lty=2,col="blue")
text(0.9,0.1982,expression(paste(lambda,"*=0.541")))
l<-Lambda[which.min(MCV)] #optimum parameter
mod <- rqss(y ~ qss(x, lambda = l), tau = tau, data = sim.data)
plot(sim.data,col="grey")
new.data<-data.frame(x=sort(c(seq(-0.999,0.999,by=0.0001),unique(sim.data$x))))
pred1<-predict(mod,newdata=new.data)
lines(as.vector(t(new.data)),pred1,lwd=2)
f<-function(x) x^2
curve(f, add=TRUE,col="red",lty=2,lwd=2)
legend("bottomleft",col=c("black","red"),lwd=2,lty=c(1,2),legend=c("Fitted median","True median"))
n <- nrow(sim.data)
s=15; b=333 #s*b ≈ n
shuffle <- sample(1:n)
indices <- matrix(head(shuffle, b * s), nrow = s, byrow = TRUE)
rboot1 <- as.vector(rmultinom(1, size = n, prob = rep(1/b,b)))
subsample <- sim.data[indices[1, ], ] # the first bag
index<-rep(1:b,rboot1)
index<-sample(index)
newdata<-subsample[index,] # the first bag with size n after resampling
nfolds<-10
cv.idx<-foldsGenerator(newdata,nfolds=nfolds)
registerDoParallel(cores=3)
Lambda<-seq(0.001,4,by=0.02)
MCV<-rep(NA,length(Lambda))
Lambda_candidates = c(0,0.05,0.1,0.15,0.2,0.3,seq(1, 30, by = 0.2),seq(30,100,by=1.5))
re<-BLB_rqss(cores=3,data=sim.data,tau=0.5,b=333,s=15,D=200,lambda = Lambda_candidates)
plot(re$Lambda[-(1:5)],re$Fid[-(1:5)],xlab=expression(lambda),ylab='CVB',type='l')
abline(v=6.4,lty=2,col="blue")
text(12,0.206,expression(paste(lambda,"*=6.4")))
library(scales)
sc<-1:201
plot(sim.data,col="grey",xlab='x',ylab='y')
ci.poly<-cbind(c(re$x0[sc],rev(re$x0[sc])),c(re$CI_average[sc, 1],rev(re$CI_average[sc, 2])))
polygon(ci.poly, col=alpha("dodgerblue3",0.6), lty=0)
lines(re$x0,re$x0^2,lwd=2)
legend("bottomleft",lwd=c(2,8),col=c("black",alpha("dodgerblue3",0.6)),legend=c("True median","Confidence bands"))
data(re)
devtools::document()
data(re)
plot(re$Lambda[-(1:5)],re$Fid[-(1:5)],xlab=expression(lambda),ylab='CVB',type='l')
abline(v=6.4,lty=2,col="blue")
text(12,0.206,expression(paste(lambda,"*=6.4")))
head(Vignette_data)
knitr::opts_chunk$set(echo = TRUE)
data(Vignette_data)
head(Vignette_data)
devtools::document()
library(ConfidenceQuant)
devtools::document()
library(ConfidenceQuant)
detach("package:ConfidenceQuant", unload=TRUE)
remove.packages("ConfidenceQuant")
install.packages("~/Desktop/ConfidenceQuant_4.1.0.tar.gz", repos = NULL, type = "source")
library(ConfidenceQuant)
set.seed(100)
f1<-function(x) sin(2*pi*x)
tau=0.5
n<-5000
x<-runif(n,-1,1)
e0<-rnorm(n,sd=0.5)
y<-x^2+e0
sim.data<-data.frame(x=x,y=y)
tau<-0.5
Lambda<-seq(0.0005,0.1,by=0.0005)
Edf<-rep(0,length(Lambda))
Fid<-rep(0,length(Lambda))
for(i in 1:length(Lambda)){
mod <- rqss(y ~ qss(x, lambda = Lambda[i]), tau = tau, data = sim.data)
Fid[i]<-mod$fidelity
Edf[i]<-mod$edf
}
plot(Lambda[-(1)],Edf[-(1)],type="l",xlab=expression(lambda),ylab=expression(p(lambda)),main="Effective Degrees of Freedom")
plot(Lambda[-(1)],(log(Fid/n)+(1/2)*(1/n)*Edf*log(n))[-(1)],type="l",xlab=expression(lambda),ylab="SIC",main=expression(paste("SIC(",lambda,") criterion")))
plot(Lambda,Fid/(n-Edf),type="l",xlab=expression(lambda),ylab="GACV",main="GACV criterion")
l1<-Lambda[16]
l2<-Lambda[17]
mod1 <- rqss(y ~ qss(x, lambda = l1), tau = tau, data = sim.data)
mod2 <- rqss(y ~ qss(x, lambda = l2), tau = tau, data = sim.data)
plot(sim.data,col="grey")
subset1<-which(abs(resid.rqss(mod1))<1e-5)
points(sim.data[subset1,],pch=20,col="red")
new.data<-data.frame(x=sort(c(seq(-0.999,0.999,by=0.0001),unique(sim.data$x))))
pred1<-predict(mod1,newdata=new.data)
lines(as.vector(t(new.data)),pred1)
plot(sim.data,col="grey")
subset2<-which(abs(resid.rqss(mod2))<1e-5)
points(sim.data[subset2,],pch=20,col="blue")
new.data<-data.frame(x=sort(c(seq(-0.999,0.999,by=0.0001),unique(sim.data$x))))
pred2<-predict(mod2,newdata=new.data)
lines(as.vector(t(new.data)),pred2)
nfolds<-10
cv.idx<-foldsGenerator(sim.data,n=nrow(sim.data),nfolds=nfolds)
require(doParallel)
require(foreach)
registerDoParallel(cores=3)
Lambda<-seq(0.001,4,by=0.02)
MCV<-rep(NA,length(Lambda))
for(m in 1:length(Lambda)){
## loop through, holding out one set of data at each point
Fid<-foreach(i = 1:nfolds,.combine="c")%dopar%{
hold.out.idx=which(cv.idx==i)
keep.in.data<-sim.data[-hold.out.idx,]
mod <- rqss(y ~ qss(x, lambda =Lambda[m]), tau = tau, data = keep.in.data)
new.data<-sim.data[hold.out.idx,]
extrapolated <- new.data$x > max(keep.in.data$x) | new.data$x < min(keep.in.data$x)
y.pred<-as.vector(predict(mod,newdata=new.data[!extrapolated,]))
mean(rho(tau=tau,x=new.data$y[!extrapolated]-y.pred))
}
MCV[m]<-mean(Fid)
}
