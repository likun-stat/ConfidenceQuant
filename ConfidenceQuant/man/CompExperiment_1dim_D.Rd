% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/CompExperiment_1dim_D.R
\name{CompExperiment_1dim_D}
\alias{CompExperiment_1dim_D}
\alias{searchLambda_1dim_D}
\title{Comparative Experiment (Discretized).}
\usage{
CompExperiment_1dim_D(cores = NULL, treatment, control, alpha = 0.05,
  tau = 0.25, lambda = 2, D = 100, s = 15,
  b1 = floor(nrow(treatment)/s), b2 = floor(nrow(control)/s), r = 100,
  M = 80, Range = c(0.001, 0.999), Search = FALSE)

searchLambda_1dim_D(lambda, Tmp, s, indices, tau, Rboot)
}
\arguments{
\item{cores}{The number of cores to use for parallel execution. If not
specified, the number of cores is set to the value of
\code{options("cores")}, if specified, or to one-half the number of cores
detected by the \code{\link{parallel}} package.}

\item{treatment}{A 2-dim optional data frame for the treatment group (or
object coercible by \code{\link{as.data.frame}} to a data frame) containing
the variables in the model. The last column of this data frame must be the
response for the experiment.}

\item{control}{A 2-dim optional data frame for the control group (or object
coercible by \code{\link{as.data.frame}} to a data frame) containing the
variables in the model. The last column of this data frame must be the
response for the experiment.}

\item{alpha}{The confidence level required. The default is 0.05.}

\item{tau}{A specific quantile to be estimated. Must be a number between 0 and
1.}

\item{lambda}{The smoothing parameter used for \code{treatment} &
\code{control} if \eqn{Search=FALSE}, which governs the tradeoff between
fidelity and the penalty component for the triogram term.}

\item{D}{A number that specifies for how many x values you want to compute
confidence intervals; the confidence band is made of pointwise intervals at
varius x values. If specified, it will look at \eqn{D} equidistant points.}

\item{s}{The number of subsamples used in the BLB algorithm. Kleiner et al.
suggest that \eqn{s} should be 10~20.}

\item{b1}{The subsample size in the BLB algorithm for \code{treatment}.
Kleiner et al. suggest that the size should be around \eqn{n1^0.6}, where
\eqn{n1} is the data size for \code{treatment}.}

\item{b2}{The subsample size in the BLB algorithm for \code{control}. It is
also suggested that the size should be around \eqn{n2^0.6}, where \eqn{n2}
is the data size for \code{control}.}

\item{r}{The number of bootstrap iterations (samples with with replacement).
\eqn{r=100} is suggested.}

\item{M}{A numeric value that controls how fine that data set should be
discretized.}

\item{Range}{A vector with 2 values that specifys the range of the data set
where the user wants to perform BLB over. It is defined using lower and
upper quantile. The default value is \eqn{(0.001,0.999)}.}

\item{Search}{If \code{TRUE} (which is recommended), then the function will
first search for an optimum smoothing parameter \eqn{\lambda}.}
}
\value{
A list with three parts - \code{result1}, \code{result2}, and
 \code{Diff}, which respectively return confidence bands for
 \code{treatment}, \code{control} and the difference between the two dataset.
 Each part includes the following:

 1. \code{x0} and \code{CI_average}, where \code{x0} contains the x values at
 which the confidence intervals are evaluated, and \code{CI_average} is 2-dim
 matrix which contains the corresponding lower and upper bounds.

 2. \code{lambda}, which is the optimum smoothing parameter selected by
 \code{BLB_Discretize}. If it is done automatically, the function also returns
 \code{Lambda} and \code{Fid}, which respectively stand for a vector of lambda
 values and their corresponding cross-validation MCV values.
}
\description{
\code{CompExperiment_1dim_D} compares the confidence bands at a given quantile
for two different datasets, one related to a treatment and the other to a
control. It applies the BLB algorithm to each dataset to get confidence bands
using quantile smoothing splines for 1-dim covariate. What's special about
this function is that it discretizes the data set to decrease the sample size,
and it utilizes ALL the observations.

\code{searchLambda_1dim_D} is a wrapper function to calculate the optimum lambda.
}
\details{
This function runs \code{BLB} twice, once for each dataset. It is based on
\code{\link{BLB_Discretize}}, which implements BLB for quantile smoothing splines
with a one dimensional covariate dataset. It performs parallelization to speed
up the calculation.

\if{html}{\figure{comp.png}{options: width=100 alt="Image output"}}
\if{latex}{\figure{comp.png}{options: width=3in}}

\code{\link{CompPlot_1dim}} takes the results and use ggplot/plotly to visualize
them, in which different colors represent different scenarios. See figure
above.
}
\examples{
data(treatment)
data(control)

#alpha=0.05;tau=0.5
all<-CompExperiment_1dim_D(cores=7,treatment,control,tau=0.5,Search=TRUE)

plot<-CompPlot_1dim(treatment = treatment, control=control, all = all, xlab = 'x', ylab = 'y')

}
\references{
Kleiner, I. J et al. JRSS B, 2012. \eqn{A Scalable Bootstrap for
 Massive Data}.

Akima, H. (1978). \eqn{A Method of Bivariate Interpolation and
 Smooth Surface Fitting for Irregularly Distributed Data Points}. ACM
 Transactions on Mathematical Software 4, 148-164.
}
\seealso{
\code{\link{contour},\link{image}}

\code{\link{BLB_rqss}} for BLB with one dataset that has 1-dim
 covariate.

\code{\link{CompExperiment_2dim}} for comparative experiments with
 2-dim covariate data sets.
}
