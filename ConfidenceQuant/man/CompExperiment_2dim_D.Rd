% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/CompExperiment_2dim_D.R
\name{CompExperiment_2dim_D}
\alias{CompExperiment_2dim_D}
\alias{searchLambda_2dim_D}
\title{Comparative Experiment (Discretized).}
\usage{
CompExperiment_2dim_D(cores = NULL, treatment, control, alpha = 0.05,
  tau = 0.25, lambda = 2, D = 50, s = 15,
  b1 = floor(nrow(treatment)/s), b2 = floor(nrow(control)/s), r = 100,
  M = 30, Range = c(0.001, 0.999), Search = FALSE)

searchLambda_2dim_D(lambda, Tmp, s, indices, tau, n, b)
}
\arguments{
\item{cores}{The number of cores to use for parallel execution. If not
specified, the number of cores is set to the value of
\code{options("cores")}, if specified, or to one-half the number of cores
detected by the \code{\link{parallel}} package.}

\item{treatment}{A 3-dim optional data frame for the treatment group (or
object coercible by \code{\link{as.data.frame}} to a data frame) containing
the variables in the model. The last column of this data frame must be the
response for the experiment.}

\item{control}{A 3-dim optional data frame for the control group (or object
coercible by \code{\link{as.data.frame}} to a data frame) containing the
variables in the model. The last column of this data frame must be the
response for the experiment.}

\item{alpha}{The confidence level required. The default is 0.05.}

\item{tau}{A specific quantile to be estimated. Must be a number between 0 and
1.}

\item{lambda}{The smoothing parameter used for \code{treatment} &
\code{control} if \eqn{Search=FALSE}, which governs the tradeoff between
fidelity and the penalty component for the triogram term.}

\item{D}{A number that determines the density of a grid of x values at which
the quantile function will be predicted. If specified, it will evaluate a
confidence surface on a \eqn{DÃ—D} grid.}

\item{s}{The number of subsamples used in the BLB algorithm. Kleiner et al.
suggest that \eqn{s} should be 10~20.}

\item{b1}{The subsample size in the BLB algorithm for \code{treatment}.
Kleiner et al. suggest that the size should be around \eqn{n1^0.6}, where
\eqn{n1} is the data size for \code{treatment}.}

\item{b2}{The subsample size in the BLB algorithm for \code{control}. It is
also suggested that the size should be around \eqn{n2^0.6}, where \eqn{n2}
is the data size for \code{control}.}

\item{r}{The number of bootstrap iterations (samples with with replacement).
\eqn{r=100} is suggested.}

\item{M}{A numeric value that controls how fine that data set should be
discretized.}

\item{Range}{A vector with 2 values that specifys the range of the data set
where the user wants to perform BLB over. It is defined using lower and
upper quantile. The default value is \eqn{(0.001,0.999)}.}

\item{Search}{If \code{TRUE} (which is recommended), then the function will
first search for an optimum smoothing parameter \eqn{\lambda}.}
}
\value{
A list with three parts - \code{result1}, \code{result2}, and
 \code{Diff}, which respectively return confidence bands for
 \code{treatment}, \code{control} and the difference between the two dataset.
 Each part includes the following:

 1. \code{x0} and \code{CI_average}, where \code{x0} contains the x values at
 which the confidence intervals are evaluated, and \code{CI_average} is 2-dim
 matrix which contains the corresponding lower and upper bounds.

 2. \code{lambda}, which is the optimum smoothing parameter selected by
 \code{BLB_Discretize_2dim}. If it is done automatically, the function also returns
 \code{Lambda} and \code{Fid}, which respectively stand for a vector of lambda
 values and their corresponding cross-validation MCV values.
}
\description{
\code{CompExperiment_2dim_D} compares the confidence regions for a given
quantile for two different datasets, one related to a treatment and the other
to a control. It applies the BLB algorithm to each dataset to get confidence
regions using quantile smoothing splines for 2-dim covariate. What's special
about this function is that it discretizes the data set to decrease the sample
size, and it utilizes ALL the observations.

\code{searchLambda_2dim_D} is a wrapper function to calculate the optimum lambda.
}
\details{
This function runs \code{BLB} twice, once for each dataset. It is based on
\code{\link{BLB_Discretize_2dim}}, which implements BLB for quantile smoothing splines
with a two-dimensional covariate dataset. It performs parallelization to speed
up the calculation.

\if{html}{\figure{comp2.png}{options: width=100 alt="Image output"}}
\if{latex}{\figure{comp2.png}{options: width=3in}}

\code{\link{CompPlot_2dim}} takes the results and use ggplot/plotly to visualize
them, in which different colors represent different scenarios. See figure
above.
}
\examples{
data(treatment_2dim)
data(control_2dim)

#alpha=0.05;tau=0.5
all<-CompExperiment_2dim_D(cores=7, treatment_2dim, control_2dim, tau=0.5, Search=TRUE)

plot<-CompPlot_2dim(control = control_2dim,treatment = treatment_2dim,all = all,xlab="x1",
ylab="x2",zlab="z")

}
\references{
Kleiner, I. J et al. JRSS B, 2012. \eqn{A Scalable Bootstrap for
Massive Data}.

Akima, H. (1978). \eqn{A Method of Bivariate Interpolation and Smooth Surface Fitting for Irregularly Distributed Data Points}. ACM Transactions on Mathematical Software 4, 148-164.
}
\seealso{
\code{\link{contour},\link{image}}

\code{\link{BLB_Discretize_2dim}} for BLB with one dataset that has 1-dim
 covariate.

\code{\link{CompExperiment_1dim_D}} for comparative experiments with
 1-dim covariate data sets.
}
