% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/CompExperiment_1dim.R
\name{CompExperiment_1dim}
\alias{CompExperiment_1dim}
\alias{searchLambda}
\alias{CompPlot_1dim}
\title{Comparative Experiment.}
\usage{
CompExperiment_1dim(cores = NULL, treatment, control, alpha = 0.05,
  tau = 0.25, lambda = 2, D = 100, b1 = ceiling(nrow(treatment)^0.6),
  b2 = ceiling(nrow(control)^0.6), s = 15, r = 100, Search = FALSE)

searchLambda(lambda, data, s, indices, tau, Rboot)

CompPlot_1dim(treatment, control, all, xlab = "x", ylab = "y",
  alpha = 0.05)
}
\arguments{
\item{cores}{The number of cores to use for parallel execution. If not
specified, the number of cores is set to the value of
\code{options("cores")}, if specified, or to one-half the number of cores
detected by the \code{\link{parallel}} package.}

\item{treatment}{A 2-dim optional data frame for the treatment group (or
object coercible by \code{\link{as.data.frame}} to a data frame) containing
the variables in the model. The last column of this data frame must be the
response for the experiment.}

\item{control}{A 2-dim optional data frame for the control group (or object
coercible by \code{\link{as.data.frame}} to a data frame) containing the
variables in the model. The last column of this data frame must be the
response for the experiment.}

\item{alpha}{The confidence level required. The default is 0.05.

 In \code{CompPlot_1dim} this stands for how many percentage of data you want
 to throw away for the final plot.}

\item{tau}{A specific quantile to be estimated. Must be a number between 0 and
1.}

\item{lambda}{The smoothing parameter governing the tradeoff between fidelity
and the penalty component for the triogram term. If \code{Search=TRUE},
there is no need for users to specify a value.}

\item{D}{A number that specifies for how many x values you want to compute
confidence intervals; the confidence band is made of pointwise intervals at
varius x values. If specified, it will look at \eqn{D} equidistant points.}

\item{b1}{The subsample size in the BLB algorithm for \code{treatment}.
Kleiner et al. suggest that the size should be around \eqn{n1^0.6}, where
\eqn{n1} is the data size for \code{treatment}.}

\item{b2}{The subsample size in the BLB algorithm for \code{control}. It is
also suggested that the size should be around \eqn{n2^0.6}, where \eqn{n2}
is the data size for \code{control}.}

\item{s}{The number of subsamples used in the BLB algorithm. Kleiner et al.
suggest that \eqn{s} should be 10~20.}

\item{r}{The number of bootstrap iterations (samples with with replacement).
\eqn{r=100} is suggested.}

\item{Search}{If \code{TRUE} (which is recommended), then the function will
first search for an optimum smoothing parameter \eqn{\lambda}.}

\item{xlab, ylab}{Titles for x and y axis. See \code{\link{title}}.}
}
\value{
A list with three parts - \code{result1}, \code{result2}, and
 \code{Diff}, which respectively return confidence bands for
 \code{treatment}, \code{control} and the difference between the two dataset.
 Each part includes the following:

 1. \code{x0} and \code{CI_average}, where \code{x0} contains the x values at
 which the confidence intervals are evaluated, and \code{CI_average} is 2-dim
 matrix which contains the corresponding lower and upper bounds.

 2. \code{lambda}, which is the optimum smoothing parameter selected by
 \code{BLB_rqss}. If it is done automatically, the function also returns
 \code{Lambda} and \code{Fid}, which respectively stand for a vector of lambda
 values and their corresponding cross-validation MCV values.
}
\description{
\code{CompExperiment_1dim} compares the confidence bands at a given quantile
for two different datasets, one related to a treatment and the other to a
control. It applies the BLB algorithm to each dataset to get confidence bands
using quantile smoothing splines for 1-dim covariate.

\code{searchLambda} is a wrapper function to calculate the optimum lambda.

\code{CompPlot_1dim} is a function to plot the results.
}
\details{
This function runs \code{BLB} twice, once for each dataset. It is based on
\code{\link{BLB_rqss}}, which implements BLB for quantile smoothing splines
with a one dimensional covariate dataset. It performs parallelization to speed
up the calculation.

\if{html}{\figure{comp.png}{options: width=100 alt="Image output"}}
\if{latex}{\figure{comp.png}{options: width=3in}}

\code{CompPlot_1dim} takes the results and use ggplot/plotly to visualize
them, in which different colors represent different scenarios. See figure
above.
}
\examples{
data(treatment)
data(control)

#alpha=0.05;tau=0.5
all<-CompExperiment_1dim(cores=7, treatment, control, tau=0.5, Search=TRUE)

plot<-CompPlot_1dim(treatment = treatment, control=control, all = all, xlab = 'x', ylab = 'y')


}
\references{
Kleiner, I. J et al. JRSS B, 2012. \eqn{A Scalable Bootstrap for
 Massive Data}.

Akima, H. (1978). \eqn{A Method of Bivariate Interpolation and
 Smooth Surface Fitting for Irregularly Distributed Data Points}. ACM
 Transactions on Mathematical Software 4, 148-164.
}
\seealso{
\code{\link{contour},\link{image}}

\code{\link{BLB_rqss}} for BLB with one dataset that has 1-dim
 covariate.

\code{\link{CompExperiment_2dim}} for comparative experiments with
 2-dim covariate data sets.
}
