% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/BLB_Discretize.R
\name{BLB_Discretize}
\alias{BLB_Discretize}
\alias{Discretize}
\title{Bag of Little Bootstraps (Discretized).}
\usage{
BLB_Discretize(cores = NULL, data, m = 80, alpha = 0.05, tau = 0.25,
  lambda = 2, D = 100, s = cores, b = floor(nrow(data)/s), r = 100,
  Range = c(0.001, 0.999), Search = FALSE)

Discretize(dats, m = 30)
}
\arguments{
\item{cores}{The number of cores to use for parallel execution. If not
specified, the number of cores is set to the value of
\code{options("cores")}, if specified, or to one-half the number of cores
detected by the \code{\link{parallel}} package.}

\item{data}{A 2-dim optional data frame (or object coercible by
\code{\link{as.data.frame}} to a data frame) containing the variables in
the model. The column names should be specified in a way that “x” is for
the predictor, and “y” for the response.}

\item{m}{A numeric value that controls how fine that data set should be
discretized.}

\item{alpha}{The confidence level required. The default is 0.05.}

\item{tau}{A specific quantile to be estimated. Must be a number between 0
and 1.}

\item{lambda}{The smoothing parameter governing the tradeoff between fidelity
and the penalty component for the triogram term. If \code{Search=TRUE},
there is no need for users to specify a value.}

\item{D}{A number that specifies for how many x values you want to compute
confidence intervals; the confidence band is made of pointwise intervals at
varius x values. If specified, it will look at \eqn{D} equidistant points.}

\item{s}{The number of subsamples used in BLB algorithm. The default value is
the number of cores the user assigned for the function.}

\item{b}{The subsample size in the BLB algorithm. Kleiner et al. suggest that
the size should be around \eqn{n^0.6}, where \eqn{n} is the data size. It
is better to have \eqn{b*s=nrow(data)} so the asymptotic property is
achieved.}

\item{r}{The number of bootstrap iterations (samples with with replacement).
\eqn{r=100} is suggested.}

\item{Range}{A vector with 2 values that specifys the range of the data set
where the user wants to perform BLB over. It is defined using lower and
upper quantile. The default value is \eqn{(0.001,0.999)}.}

\item{Search}{If \code{TRUE} (which is recommended), then the function will
first search for an optimum smoothing parameter \eqn{\lambda}.}
}
\value{
A list with three parts:

  1. \code{x0} and \code{CI_average}, where \code{x0} contains the x values
  at which the confidence intervals are evaluated, and \code{CI_average} is
  2-dim matrix which contains the corresponding lower and upper bounds.

  2. \code{lambda}, which is the optimum smoothing parameter selected by
  \code{BLB_Discretize}. If it is done automatically, the function also
  returns \code{Lambda} and \code{Fid}, which respectively stand for a vector
  of lambda values and their corresponding cross-validation MCV values.
}
\description{
\code{BLB_Discretize}  Bag of Litle Bootstraps (BLB) for data sets with 1-dim
covariate. Used to generate  confidence bands for a quantile smoothing
splines fitted with the rqss function from package \code{\link{quantreg}}.
What's special about this function is that it discretizes the data set to
decrease the sample size, and it utilizes ALL the observations.

\code{Discretize} is a function to discretize the data set.
}
\details{
This function is based on the "Bag of Little Bootstraps" (BLB) method by
Kleiner et al.(2012). It performs parallelization to speed up the
calculation.
}
\examples{
data(one)
result<-BLB_Discretize(cores=7,data=one, alpha=0.05, tau=0.5, Search=TRUE)

plot<-FitPlot_1dim(data=one, result=result, xlab='x',ylab='y')
plot


}
\references{
Micheal, I. J et al.(2012). \eqn{A Scalable Bootstrap for Massive
  Data}.
}
\seealso{
\code{\link{BLB_Discretize_2dim}} for BLB with 2-dim covariate
  dataset.
}
